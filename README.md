# How Do Vision Transformers See Depth in Single Images?

![Position and Scale Image Sequence](sr4ad/img/pos_vs_scale___normal.gif)
![Position and Scale Image Sequence](sr4ad/img/pos_vs_scale___pos_only.gif)
![Position and Scale Image Sequence](sr4ad/img/pos_vs_scale___scale_only.gif)

[\[Slides\]](https://sr4ad-vit-mde.github.io/web-slides/sr4ad/presentation.html) 
[\[Blog Post\]](https://sr4ad-vit-mde.github.io/blog/2023/visual-cues-monocular-depth-estimation/) 
[\[OpenReview\]](https://openreview.net/group?id=ICLR.cc/2023/Workshop/SR4AD)


This repo hosts the presentation slides for the [SR4AD](https://opendrivelab.com/sr4ad/iclr23) workshop submission on `How Do Vision Transformers See Depth in Single Images?` at the [ICLR 2023](https://iclr.cc/).

The web slides were created using [reveal.js](https://github.com/hakimel/reveal.js/) and the interactive visualizations were created using [plotly's HTML export](https://plotly.com/python/interactive-html-export/).

--- 

This submission is a research insight on the original work from Tom Van Dijk and Guido de Croon.
Their source code is available [here on GitHub](https://github.com/tomvand/2019-iccv-depthcues).
If you find it useful, please cite their work:

```
@InProceedings{Dijk_2019_ICCV,
author = {Dijk, Tom van and Croon, Guido de},
title = {How Do Neural Networks See Depth in Single Images?},
booktitle = {The IEEE International Conference on Computer Vision (ICCV)},
month = {October},
year = {2019}
} 
```
